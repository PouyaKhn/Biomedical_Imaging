# -*- coding: utf-8 -*-
"""tasks1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/196vOw39G254YBL82qrJeB-xB6wrd0ZaP

# Image Enhancement Using Transformation
"""

import cv2
import matplotlib.pyplot as plt
import numpy as np

from google.colab import drive
drive.mount('/content/my-drive')

def plot_img(image, edited, title1, title2, cmap_val='gray'):
    
    fig = plt.figure(figsize=(10, 20))

    ax1 = fig.add_subplot(2, 2, 1)
    ax1.axis("off")
    ax1.title.set_text(title1)
    ax2 = fig.add_subplot(2, 2, 2)
    ax2.axis("off")
    ax2.title.set_text(title2)

    ax1.imshow(image, cmap=cmap_val)
    ax2.imshow(edited, cmap=cmap_val)
    plt.axis('off')

image1 = cv2.imread(r'/content/Image1.png')
image1 = cv2.resize(image1, (256, 256))
brain_image = image1.copy()

print(type(brain_image))
print(brain_image.shape)
print(brain_image.dtype)
plt.figure(figsize=(5,14))
plt.imshow(brain_image)
plt.title('Original')
plt.axis('off')

"""## Log Transformation"""

##Log transform
import math
def log_trans(img):
    height, width = img.shape[0:2]
    val = img.flatten()
    maxv = max(val)
    
    c = 255/(math.log(1 + maxv))
    
    for i in range(height):
        for j in range(width):

            new_val = int(c * (math.log( 1 + int(img[i][j]))))
            
            if new_val > 255:
              new_val = 255
            img[i][j] = new_val

    return img

brain_img = brain_image[:,:,0]
log_image = log_trans(brain_img.copy())
plot_img(image1, log_image, 'Original', 'Gray level tranform')

"""## Sharping"""

## Sharping
kernel = np.array([[0, -1, 0],
                   [-1, 4.9, -1],
                   [0, -1, 0]])

image_sharp = cv2.filter2D(src = log_image, ddepth = -1, kernel = kernel)
plot_img(image1, image_sharp, 'Original', 'Sharpen')

"""# Image Enhancement Using increasing Contrast"""

img = np.asarray(image_sharp)

flat = img.flatten()

plt.figure(figsize=(8,6))
plt.hist(flat, bins=100)

# PMF of all the pixels
def get_histogram(image, bins):
    
    histogram = np.zeros(bins, dtype=int)
    
    for pixel in image:
        histogram[pixel] += 1
    
    return histogram


hist = get_histogram(img, 256)

def cumsum_func(histogram):
    cumsum = np.zeros(256, dtype=int)
    cumsum[0] = histogram[0]
    for i in range(1, histogram.size):
        cumsum[i] = cumsum[i-1] + histogram[i]
    return cumsum
    
cs = cumsum_func(hist)

nj = (cs - cs.min()) * 255
N = cs.max() - cs.min()

# re-normalize the cumsum
cs = nj / N

# back to uint8
# can't use floating point values in images
cs = cs.astype('uint8')

img_new = cs[flat]
img_new = img_new.reshape(img.shape)
plot_img(image1, img_new.reshape(img.shape),'Original', 'Enhance_contrast')

img1 = np.asarray(img_new)

flat1 = img1.flatten()

plt.figure(figsize=(8,6))
plt.hist(flat1, bins=100)

"""# Image Enhancement Using Deep Learning

Work on this dataset:

https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection


"""

from keras.preprocessing import image
from keras.layers import add, Conv2D, Input, Reshape
import tensorflow as tf

tf.config.list_physical_devices('GPU')
tf.test.gpu_device_name()

def apply_lowcontrast(image, intensity):
  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #convert it to hsv
  hsv[...,2] = hsv[...,2] * intensity
  return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

def add_noise(image):
  noisy_image = image + 0.23 * np.random.randn(*image.shape)
  noisy_image = np.clip(noisy_image, 0, 1)
  return noisy_image

def PreProcessData(ImagePath):
    X = []
    y = []
    for imageDir in list(os.listdir(ImagePath)):

        img = image.load_img(ImagePath + imageDir)
        img = image.img_to_array(img)
        img = img/255
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img_y = cv2.resize(img, (256,256))

        intensity = np.random.randint(5, 90)/1000.0

        noised_img = add_noise(img_y)
        lowLightImg_x = apply_lowcontrast(img_y, intensity)

        X.append(lowLightImg_x)
        y.append(img_y)

    X1 = np.array(X)
    y1 = np.array(y)
    
    return X1,y1

import os
path = '/content/my-drive/My Drive/MRI Brain/'
X_train , y_train = PreProcessData(path)

Input_Sample = Input(shape=(256, 256, 3))
###-------------------------------------------------------------------------------------
model_1 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(Input_Sample)
model_1 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_1)
model_1 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_1)
###-------------------------------------------------------------------------------------    
model_2 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(Input_Sample)
model_2 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_2)
###-------------------------------------------------------------------------------------    
model_2_1 = Conv2D(64,(2,2), activation='relu',padding='same',strides=1)(model_2)
#-------------------------------------###ADD###-----------------------------------------   
model_add_1 = add([model_1, model_2, model_2_1])

#------------------------------------#Extension#----------------------------------------    
model_3 = Conv2D(64,(3,3), activation='relu',padding='same',strides=1)(model_add_1)
model_3 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_3)
model_3 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_3)
###-------------------------------------------------------------------------------------    
model_3_1 = Conv2D(32,(3,3), activation='relu',padding='same',strides=1)(model_add_1)
model_3_1 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_3_1)
###-------------------------------------------------------------------------------------    
model_3_2 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_add_1)
#-------------------------------------###ADD###-----------------------------------------     
model_add_2 = add([model_3_1, model_3_2, model_3])

#------------------------------------#Extension#----------------------------------------    
model_4 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add_2)
###-------------------------------------------------------------------------------------
model_4_1 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add_1)
#-------------------------------------###ADD###----------------------------------------- 
model_add_3 = add([model_4_1, model_add_2, model_4])

#------------------------------------#Extension#----------------------------------------    
model_5 = Conv2D(16,(3,3), activation='relu',padding='same',strides=1)(model_add_3)
model_5 = Conv2D(16,(2,2), activation='relu',padding='same',strides=1)(model_add_3)

model_5 = Conv2D(3,(3,3), activation='relu',padding='same',strides=1)(model_5)

from keras.models import Model

Model_Enhancer = Model(inputs=Input_Sample, outputs=model_5)

Model_Enhancer.compile(optimizer = 'adam', loss='mean_squared_error')
Model_Enhancer.summary()

"""<div dir="rtl">
<font face="XB Zar" size=5>
    <h1>
    </h1>
epoch * steps_per_epoch < number of images in dataset
</font>
</div>
"""

def GenerateInputs(X, y):
    for i in range(len(X)):
        X_input = X[i].reshape(1, 256, 256, 3)
        y_input = y[i].reshape(1, 256, 256, 3)
        yield (X_input,y_input)

history = Model_Enhancer.fit(GenerateInputs(X_train, y_train), epochs=25, verbose=1, steps_per_epoch = 10, shuffle=True)

brain_image1 = brain_image.copy()
Prediction = Model_Enhancer.predict(brain_image1.reshape(1, 256, 256, 3))
Prediction = Prediction.reshape(256,256,3)
brain_image1[:,:,:] = Prediction[:,:,:]
plot_img(brain_image, brain_image1[:,:,0], 'Original', 'Enhanced & Denoised')

"""# Denoising image using Median Filter"""

def median_filter(img, size):
    r_img = img.copy()
    height, width = r_img.shape[0:2]
    for row in range(size, height-size):
        for column in range(size, width-size):
            r_img[row][column] = np.median(r_img[row - size : row + (size+1), column - size : column + (size+1)])
            
    return r_img

size = int(input("Enter the size of filter: "))
r_img = median_filter(img_new, size)

plot_img(img_new, r_img, 'Before filtering', 'Denoising')

"""# Denoising using Autoencoder"""

from keras.models import Model
from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input
from tensorflow.keras.optimizers import SGD, Adam
import tensorflow as tf

from google.colab import drive
drive.mount('/content/my-drive')

import os
train_images=sorted(os.listdir('my-drive/My Drive/MRI Brain')) #Taking a list of the images' name then sorting

from keras.preprocessing import image

# Read images from the dataset and add
# Normalize images and turn to list of arrays

train_image=[]
for im in train_images:
  img=image.load_img('my-drive/My Drive/MRI Brain/'+im, target_size=(256,256),color_mode='grayscale')
  img=image.img_to_array(img)
  img=img/255
  train_image.append(img)

train_df=np.array(train_image)

#Subplotting 5 images
def plot_image(dataset):
  f,ax=plt.subplots(1,5)
  f.set_size_inches(30,10)
  for i in range(5,10):
    ax[i-5].imshow(dataset[i].reshape(256,256), cmap='gray')
    ax[i-5].axis('off')
  plt.show()

#Adding random noise
def add_noise(image):
  noisy_image = image + 0.24 * np.random.randn(*image.shape)
  noisy_image = np.clip(noisy_image, 0, 1)
  return noisy_image

# Add noise to each image
noised_df=[]
for img in train_df:
  noisy=add_noise(img)
  noised_df.append(noisy)

noised_df=np.array(noised_df)

plot_image(train_df)

plot_image(noised_df)

xnoised = noised_df[:121] # X train --> Noisy images for training
xtestnoised = noised_df[121:] # X test --> Noisy images for validation and test
xtrain = train_df[:121] # y train --> without noise
xtest = train_df[121:] # y test --> without noise

input = Input(shape=(256,256,1))
#enoder 
x = Conv2D(64, (3,3), activation='relu', padding='same')(input)
x1 = MaxPooling2D((2,2), padding='same')(x)
x2 = Conv2D(64, (3,3), activation='relu', padding='same')(x1)
x3 = MaxPooling2D((2,2), padding='same')(x2)
   
#decoder
x4 = Conv2D(64, (3,3), activation='relu', padding='same')(x3)
x5 = UpSampling2D((2,2))(x4)
x6 = Conv2D(64, (3,3), activation='relu', padding='same')(x5)
x7 = UpSampling2D((2,2))(x6)
x8 = Conv2D(1, (3,3), activation='sigmoid', padding='same')(x7)
   
#model
autoencoder = Model(inputs=input, outputs=x8)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

autoencoder.summary()

autoencoder.fit(xnoised, 
                xtrain, 
                epochs=20, 
                batch_size=10, 
                validation_data=(xtestnoised, xtest))

dtest = []
for images in xtestnoised[8:18]:
  dtest.append(images)

# Normalizing my own image test and add it to the testing images list
img1=image.img_to_array(img_new)
img1=img1/255
dtest.append(img1)
dtest_arr = np.array(dtest)

pred= autoencoder.predict(dtest_arr)

plot_image(dtest_arr) #Plotting 5 first images before denoising

plot_image(pred) #Plotting after denoising

plot_img(img_new, pred[10].reshape(256,256), 'Before Denoising', 'After Autoencoder Denoising')

"""# Edge Detection Using Highpass filtering"""

### Fourier Transform --> Real and Imaginary value

F1 = np.fft.fft2(r_img)
F2 = np.fft.fftshift(F1) # Zero frequency in the center of the image
mag = 20 * np.log(np.abs(F2) + 1e-6) #Saving the complex numbers as real numbers

plot_img(r_img, mag, 'Before', 'After')

(w, h) = r_img.shape
half_w, half_h = np.int32(w/2), np.int32(h/2)

#### highpass filter
n = 20 # The higher the number, the higher scales of the image therefore the details are much less shown

F2[ half_w-n:half_w+n+1 , half_h-n:half_h+n+1 ] = 0 # select all but the first 40x40 (low) frequencies

mag1 = 20 * np.log(np.abs(F2) + 1e-6)

plot_img(r_img, mag1, 'Before', 'After')

mag2 = np.fft.ifft2(np.fft.ifftshift(F2)) # Inverse Fourier Transform
mag2 = np.real(mag2) #Taking only the real values
plot_img(r_img, mag2, 'Before', 'Edge detection')

plot_img(r_img, r_img+mag2, 'Before', 'After')